{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from nibabel.streamlines import load as load_trk\n",
    "import dipy.tracking.streamline as dts\n",
    "import dipy.tracking.utils as dtu\n",
    "from skimage.transform import resize\n",
    "from scipy.ndimage.morphology import binary_dilation\n",
    "import dipy.data as dpd\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import  Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bundlenet as bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.bag as db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AF_L.trk             CCMid.trk  CST_R.trk   IFOF_L.trk\r\n",
      "AF_R.trk             C_L.trk    F_L.trk     MCP.trk\r\n",
      "CC_ForcepsMajor.trk  C_R.trk    F_R.trk     UF_L.trk\r\n",
      "CC_ForcepsMinor.trk  CST_L.trk  IF0F_R.trk  UF_R.trk\r\n"
     ]
    }
   ],
   "source": [
    "ls /home/ubuntu/Atlas_in_MNI_Space_16_bundles/bundles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_files = sorted(glob('/home/ubuntu/Atlas_in_MNI_Space_16_bundles/bundles/*.trk'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182, 218, 182)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_img = nib.load('/home/ubuntu/MNI152_T1_1mm_brain.nii.gz')\n",
    "vol_shape=diff_img.shape[0:3]\n",
    "vol_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ubuntu/Atlas_in_MNI_Space_16_bundles/bundles/AF_L.trk',\n",
       " '/home/ubuntu/Atlas_in_MNI_Space_16_bundles/bundles/AF_R.trk',\n",
       " '/home/ubuntu/Atlas_in_MNI_Space_16_bundles/bundles/CCMid.trk',\n",
       " '/home/ubuntu/Atlas_in_MNI_Space_16_bundles/bundles/CC_ForcepsMajor.trk',\n",
       " '/home/ubuntu/Atlas_in_MNI_Space_16_bundles/bundles/CC_ForcepsMinor.trk',\n",
       " '/home/ubuntu/Atlas_in_MNI_Space_16_bundles/bundles/CST_L.trk',\n",
       " '/home/ubuntu/Atlas_in_MNI_Space_16_bundles/bundles/CST_R.trk',\n",
       " '/home/ubuntu/Atlas_in_MNI_Space_16_bundles/bundles/C_L.trk',\n",
       " '/home/ubuntu/Atlas_in_MNI_Space_16_bundles/bundles/C_R.trk',\n",
       " '/home/ubuntu/Atlas_in_MNI_Space_16_bundles/bundles/F_L.trk',\n",
       " '/home/ubuntu/Atlas_in_MNI_Space_16_bundles/bundles/F_R.trk',\n",
       " '/home/ubuntu/Atlas_in_MNI_Space_16_bundles/bundles/IF0F_R.trk',\n",
       " '/home/ubuntu/Atlas_in_MNI_Space_16_bundles/bundles/IFOF_L.trk',\n",
       " '/home/ubuntu/Atlas_in_MNI_Space_16_bundles/bundles/MCP.trk',\n",
       " '/home/ubuntu/Atlas_in_MNI_Space_16_bundles/bundles/UF_L.trk',\n",
       " '/home/ubuntu/Atlas_in_MNI_Space_16_bundles/bundles/UF_R.trk']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bundle_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#streamlines_all = bn.read_sl('/home/ubuntu/Atlas_in_MNI_Space_16_bundles/whole_brain/whole_brain_MNI.trk') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'streamlines_all_mni=[]\\nt=np.zeros([len(streamlines_all),3])\\nfor i in range(len(streamlines_all)):\\n    tmp = streamlines_all[i]\\n    tmp2=np.zeros([len(tmp),3])\\n    tmp2[:,0] = tmp[:,0] * -1 + 90\\n    tmp2[:,1] = tmp[:,1] + 126\\n    tmp2[:,2] = tmp[:,2] + 72\\n    streamlines_all_mni.append(np.round(tmp2))\\n    t[i,0]=np.max(np.round(tmp2[:,0]))\\n    t[i,1]=np.max(np.round(tmp2[:,1]))\\n    t[i,2]=np.max(np.round(tmp2[:,2]))\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''streamlines_all_mni=[]\n",
    "t=np.zeros([len(streamlines_all),3])\n",
    "for i in range(len(streamlines_all)):\n",
    "    tmp = streamlines_all[i]\n",
    "    tmp2=np.zeros([len(tmp),3])\n",
    "    tmp2[:,0] = tmp[:,0] * -1 + 90\n",
    "    tmp2[:,1] = tmp[:,1] + 126\n",
    "    tmp2[:,2] = tmp[:,2] + 72\n",
    "    streamlines_all_mni.append(np.round(tmp2))\n",
    "    t[i,0]=np.max(np.round(tmp2[:,0]))\n",
    "    t[i,1]=np.max(np.round(tmp2[:,1]))\n",
    "    t[i,2]=np.max(np.round(tmp2[:,2]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nstreamline_all_bundle=np.zeros([len(streamlines_all),1])\\nn_streamlines = []\\nbundle_names = []\\nstreamlines_seg = []\\nfor f, fname in enumerate(bundle_files):\\n    print(f)\\n    bundle_names.append(fname.split('/')[-1].split('bundles_')[-1].split('.trk')[0])\\n    streamlines = bn.read_sl(fname) \\n    #streamlines_seg = streamlines_seg+streamlines\\n    for s_idx, s in enumerate(streamlines):\\n        for ss_idx, ss in enumerate(streamlines_all):\\n            if np.array_equal(s,ss):\\n                streamline_all_bundle[ss_idx]=f+1\\n                break\\n    n_streamlines.append(len(streamlines))\\n\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "streamline_all_bundle=np.zeros([len(streamlines_all),1])\n",
    "n_streamlines = []\n",
    "bundle_names = []\n",
    "streamlines_seg = []\n",
    "for f, fname in enumerate(bundle_files):\n",
    "    print(f)\n",
    "    bundle_names.append(fname.split('/')[-1].split('bundles_')[-1].split('.trk')[0])\n",
    "    streamlines = bn.read_sl(fname) \n",
    "    #streamlines_seg = streamlines_seg+streamlines\n",
    "    for s_idx, s in enumerate(streamlines):\n",
    "        for ss_idx, ss in enumerate(streamlines_all):\n",
    "            if np.array_equal(s,ss):\n",
    "                streamline_all_bundle[ss_idx]=f+1\n",
    "                break\n",
    "    n_streamlines.append(len(streamlines))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_streamlines = []\n",
    "bundle_names = []\n",
    "for fname in bundle_files:\n",
    "    bundle_names.append(fname.split('/')[-1].split('bundles_')[-1].split('.trk')[0])\n",
    "    streamlines = bn.read_sl(fname) \n",
    "    n_streamlines.append(len(streamlines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 16)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(n_streamlines), len(n_streamlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "take_n_bundles = len(n_streamlines)\n",
    "take_n_sl = np.min(n_streamlines)\n",
    "\n",
    "test_perc=0.2\n",
    "val_perc=0.2\n",
    "size_slimage = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import imp  \n",
    "imp.reload(bn)\n",
    "\n",
    "#if op.exists('./subject1_bundles.npz'):\n",
    "    # Read it from file:\n",
    "   # loaded_from_file = np.load('./subject1_bundles.npz')\n",
    "    #labels_test = loaded_from_file['labels_test']\n",
    "    #labels_val = loaded_from_file['labels_val']\n",
    "    #labels_train = loaded_from_file['labels_train']\n",
    "    #data_test = loaded_from_file['data_test']\n",
    "   # data_val = loaded_from_file['data_val']\n",
    "    #data_train = loaded_from_file['data_train']\n",
    "#else:\n",
    "streamlines_loaded = db.from_sequence(bundle_files).map(bn.read_sl_mni).compute()\n",
    "streamlines_processed = db.from_sequence(streamlines_loaded).map(bn.process_sl,take_n_sl,vol_shape,size_slimage,5).compute() \n",
    "data_train, data_test, data_val, labels_train, labels_test, labels_val = bn.partition_testtrain(test_perc, val_perc, streamlines_processed)\n",
    "np.savez('./atlas_bundles', data_train=data_train, labels_train=labels_train, data_val=data_val, labels_val=labels_val, data_test=data_test, labels_test=labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5fc6645940>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(streamlines_processed[5][1,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = size_slimage\n",
    "img_cols = size_slimage\n",
    "batch_size = 4\n",
    "epochs = 5\n",
    "num_classes = take_n_bundles\n",
    "input_shape = (img_rows, img_cols,1)\n",
    "pool_size = 2\n",
    "kernel_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define two groups of layers: feature (convolutions) from unet and classification (dense)\n",
    "feature_layers = [\n",
    "    Conv2D(64, kernel_size,\n",
    "           padding='same',\n",
    "           input_shape=input_shape),\n",
    "    Activation('relu'),\n",
    "     Conv2D(64, kernel_size,\n",
    "           padding='same'),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    \n",
    "    Conv2D(128, kernel_size,\n",
    "           padding='same'),\n",
    "    Activation('relu'),\n",
    "     Conv2D(128, kernel_size,\n",
    "           padding='same'),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    \n",
    "    Conv2D(256, kernel_size,\n",
    "           padding='same'),\n",
    "    Activation('relu'),\n",
    "     Conv2D(256, kernel_size,\n",
    "           padding='same'),\n",
    "    Activation('relu'),\n",
    "    Conv2D(256, kernel_size,\n",
    "           padding='same'),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    \n",
    "    Conv2D(512, kernel_size,\n",
    "           padding='same'),\n",
    "    Activation('relu'),\n",
    "     Conv2D(512, kernel_size,\n",
    "           padding='same'),\n",
    "    Activation('relu'),\n",
    "    Conv2D(512, kernel_size,\n",
    "           padding='same'),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    \n",
    "    Conv2D(512, kernel_size,\n",
    "           padding='same'),\n",
    "    Activation('relu'),\n",
    "     Conv2D(512, kernel_size,\n",
    "           padding='same'),\n",
    "    Activation('relu'),\n",
    "    Conv2D(512, kernel_size,\n",
    "           padding='same'),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    \n",
    "    Flatten()\n",
    "]\n",
    "\n",
    "classification_layers = [\n",
    "    Dense(1024),\n",
    "    Activation('relu'),\n",
    "    Dense(5),\n",
    "    Activation('softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_resize = np.zeros((len(x_train),size_slimage,size_slimage))\n",
    "for i in range(len(x_train)):\n",
    "    x_train_resize[i,:,:] = resize(x_train[i,:,:],(size_slimage,size_slimage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_resize = np.zeros((len(x_test),size_slimage,size_slimage))\n",
    "for i in range(len(x_test)):\n",
    "    x_test_resize[i,:,:] = resize(x_test[i,:,:],(size_slimage,size_slimage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train, test, num_classes):\n",
    "    x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
    "    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(train[1], num_classes)\n",
    "    y_test = keras.utils.to_categorical(test[1], num_classes)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    t = now()\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "    print('Training time: %s' % (now() - t))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(feature_layers + classification_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_resize_lt5 = x_train_resize[y_train < 5]\n",
    "y_train_lt5 = y_train[y_train < 5]\n",
    "x_test_resize_lt5 = x_test_resize[y_test < 5]\n",
    "y_test_lt5 = y_test[y_test < 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30596,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_lt5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (20000, 100, 100, 1)\n",
      "20000 train samples\n",
      "5139 test samples\n",
      "Train on 20000 samples, validate on 5139 samples\n",
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 526s 26ms/step - loss: 1.6102 - acc: 0.2213 - val_loss: 1.6092 - val_acc: 0.2209\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 525s 26ms/step - loss: 1.6081 - acc: 0.2236 - val_loss: 1.6083 - val_acc: 0.2209\n",
      "Epoch 3/5\n",
      " 9868/20000 [=============>................] - ETA: 4:11 - loss: 1.6083 - acc: 0.2216"
     ]
    }
   ],
   "source": [
    "train_model(model,\n",
    "            (x_train_resize_lt5[0:20000,:,:], y_train_lt5[0:20000]),\n",
    "            (x_test_resize_lt5[0:20000,:,:], y_test_lt5[0:20000]),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"checkpoints/weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#create checkpoints dir\n",
    "training = model.fit(data_train, labels_train,\n",
    "                     batch_size=batch_size,\n",
    "                     epochs=epochs,\n",
    "                     verbose=1,\n",
    "                     validation_data=(data_val, labels_val),\n",
    "                     callbacks=callbacks_list,\n",
    "                     class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"checkpoints/weights.best.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(data_test, labels_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = bn.plot_accuracy(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict(data_test, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_idx = np.argmax(p, axis=-1)\n",
    "labels_test_idx = np.argmax(labels_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn.print_accuarcystats(p_idx,labels_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn.plotconfusionmat(bundle_names, p_idx, labels_test_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-predict on *another subject*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2_t1_img = nib.load('/home/ubuntu/MNI152_T1_1mm_brain.nii.gz')\n",
    "vol_shape_subj2=sub2_t1_img.shape[0:3]\n",
    "vol_shape_subj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlines_all = bn.read_sl_mni('/home/ubuntu/recobundles/100307/out_work/whole_brain_MNI_tracks_from_sh__moved.trk') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import imp  \n",
    "imp.reload(bn)\n",
    "streamlines_processed=[]\n",
    "for i in range(int(np.max(streamline_all_bundle))):\n",
    "    print(i)\n",
    "    indices = np.int_(np.where(streamline_all_bundle==i)[0])\n",
    "    streamlines_tract = [streamlines_all[j] for j in indices]\n",
    "    streamlines_processed_tract = bn.process_sl(streamlines_tract,take_n_sl,vol_shape,size_slimage,5)\n",
    "    streamlines_processed.append(streamlines_processed_tract)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_files = sorted(glob('/home/ubuntu/recobundles/100307/out_work/rrbs/whole_brain_MNI_tracks_from_sh__moved_*.npy'))\n",
    "map_file_index = []\n",
    "labels_subj2 = []\n",
    "for m_idx, m in enumerate(map_files):\n",
    "    tmp = np.load(m)\n",
    "    map_file_index = np.append(map_file_index,tmp)\n",
    "    labels_subj2 = np.append(labels_subj2,m_idx*np.ones([len(tmp),1]))\n",
    "labels_subj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = range(len(streamlines_all))\n",
    "ind = np.delete(ind,map_file_index)\n",
    "np.random.shuffle(ind)\n",
    "unlabeled_streamlines = ind[0:len(map_file_index)]\n",
    "labels_subj2 = np.append(labels_subj2,16*np.ones([len(map_file_index),1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_subj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.append(map_file_index,unlabeled_streamlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlines_all_sub = [streamlines_all[i] for i in np.int_(np.append(map_file_index,unlabeled_streamlines))]\n",
    "len(streamlines_all_sub)\n",
    "len(labels_subj2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp  \n",
    "imp.reload(bn)\n",
    "streamlines_all_processed = bn.process_sl(streamlines_all_sub,-1,vol_shape_subj2,size_slimage,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = np.load(map_files[0])\n",
    "tmp2 = np.load(map_files[1])\n",
    "tmp = np.append(tmp1,tmp2)\n",
    "streamlines_bund1 = [streamlines_all[i] for i in np.int_(tmp)]\n",
    "streamlines_bund1_processed = bn.process_sl(streamlines_bund1,-1,vol_shape_subj2,size_slimage,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(streamlines_all_processed[10000,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_subj2 = model.predict(streamlines_all_processed, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_idx = np.argmax(p_subj2, axis=-1)\n",
    "max(p_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn.print_accuarcystats(p_idx[labels_subj2<16],labels_subj2[labels_subj2<16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(p_subj2.max(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(labels_subj2==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p_idx[labels_subj2==0]==0)\n",
    "len(p_idx[labels_subj2==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn.plotconfusionmat(bundle_names, p_idx, labels_subj2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_error = p_subj2[~(p_idx == all_labels)]\n",
    "p_correct = p_subj2[p_idx == all_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "ax.hist(np.max(p_correct, -1), histtype='step', linewidth=2, normed=True, bins=10, label=\"Correct\")\n",
    "ax.hist(np.max(p_error, -1), histtype='step', linewidth=2, normed=True, bins=10, label=\"Incorrect\")\n",
    "ax.set_xlabel(\"Probability of chosen category\")\n",
    "ax.set_ylabel(\"Normalized frequency\")\n",
    "plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi_img = nib.load('/home/ubuntu/stanford_hardi/derivatives/afq/sub-01/sess-01/sub-01_sess-01_dwi_b0.nii.gz')\n",
    "vol_shape_dwi=dwi_img.shape\n",
    "vol_shape_dwi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp  \n",
    "imp.reload(bn)\n",
    "\n",
    "stan_loaded = db.from_sequence([\"/home/ubuntu/stanford_hardi/derivatives/afq/sub-01/sess-01/clean_bundles/CST_R.trk\"]).map(bn.read_sl).compute()\n",
    "stan_streamlines_processed = db.from_sequence(stan_loaded).map(bn.process_sl,size_slimage,vol_shape_dwi,size_slimage,5).compute() \n",
    "tmp = stan_streamlines_processed[0]\n",
    "plt.matshow(np.squeeze(np.sum(tmp,axis=0))) \n",
    "tmp1 = tmp[:,:,0,:]\n",
    "plt.matshow(np.squeeze(tmp[10,:,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_loaded = db.from_sequence([bundle_files[22]]).map(bn.read_sl).compute()\n",
    "atlas_streamlines_processed = db.from_sequence(atlas_loaded).map(bn.process_sl,100,vol_shape,size_slimage,5).compute() \n",
    "tmp = atlas_streamlines_processed[0]\n",
    "plt.matshow(np.squeeze(np.sum(tmp,axis=0)))\n",
    "tmp1 = tmp[:,:,0,:]\n",
    "plt.matshow(np.squeeze(tmp[1,:,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in enumerate(bundle_files):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_files_afq = glob('/home/ubuntu/stanford_hardi/derivatives/afq/sub-01/sess-01/clean_bundles/*.trk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlines_loaded_afq = db.from_sequence(bundle_files_afq).map(bn.read_sl).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del streamlines_processed_afq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sl = 1000\n",
    "streamlines_processed_afq = db.from_sequence(streamlines_loaded_afq).map(bn.process_sl,num_sl,vol_shape_dwi,size_slimage,5).compute() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(streamlines_loaded_afq[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_streamlines_afq, all_labels_afq = bn.getdatafrombag(streamlines_processed_afq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_afq = model.predict(all_streamlines_afq, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_idx_afq = np.argmax(p_afq, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_names_afq = []\n",
    "for fname in bundle_files_afq:\n",
    "    bundle_names_afq.append(fname.split('/')[-1].split('bundles_')[-1].split('.trk')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stat\n",
    "\n",
    "prob = np.max(p_afq,axis=-1)\n",
    "\n",
    "for i in range(len(bundle_names_afq)):\n",
    "    print(\"AFQ bundle= \" + str(bundle_names_afq[i]))\n",
    "    tmp = p_idx_afq[(num_sl*i):(num_sl-1)+(num_sl*i)]\n",
    "    unique, counts = np.unique(tmp, return_counts=True)\n",
    "    ctsinds = counts.argsort()\n",
    "    sorted_unique = unique[ctsinds[::-1]]\n",
    "    m1 = sorted_unique[0]\n",
    "    m2 = sorted_unique[1]\n",
    "    print(\"Most likely bundle= \" + str(bundle_names[m1]))\n",
    "    print(\"2nd Most likely bundle= \" + str(bundle_names[m2]))\n",
    "    tmp2 = prob[(num_sl*i):(num_sl-1)+(num_sl*i)]\n",
    "    p = np.mean(tmp2)\n",
    "    p2 = np.mean(tmp2[tmp==m1])\n",
    "    print(\"Mean probability over all SLs= \" + str(p))\n",
    "    print(\"Mean probability over 'correct' SLs= \" + str(p2))\n",
    "    c = sum(tmp==m1)\n",
    "    print(\"Fraction of SLs with most likely class= \" + str(c/num_sl))\n",
    "    c = sum(tmp==m2)\n",
    "    print(\"Fraction of SLs with 2nd most likely class= \" + str(c/num_sl))\n",
    "    print(\"        \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(tmp, return_counts=True)\n",
    "counts\n",
    "ctsinds = counts.argsort()\n",
    "sorted_unique = unique[ctsinds[::-1]]\n",
    "print(counts)\n",
    "print(unique)\n",
    "sorted_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_files_afq2 = glob('/home/ubuntu/stanford_hardi/derivatives/afq/sub-01/sess-01/bundles/*.trk')\n",
    "streamlines_loaded_afq2 = db.from_sequence(bundle_files_afq2).map(bn.read_sl).compute()\n",
    "num_sl = 1000\n",
    "streamlines_processed_afq2 = db.from_sequence(streamlines_loaded_afq2).map(bn.process_sl,num_sl,vol_shape_dwi,size_slimage,1).compute() \n",
    "all_streamlines_afq2, all_labels_afq2 = bn.getdatafrombag(streamlines_processed_afq2)\n",
    "p_afq = model.predict(all_streamlines_afq2, batch_size=5)\n",
    "p_idx_afq = np.argmax(p_afq, axis=-1)\n",
    "bundle_names_afq2 = []\n",
    "for fname in bundle_files_afq2:\n",
    "    bundle_names_afq2.append(fname.split('/')[-1].split('bundles_')[-1].split('.trk')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stat\n",
    "\n",
    "prob = np.max(p_afq,axis=-1)\n",
    "\n",
    "for i in range(len(bundle_names_afq2)):\n",
    "    print(\"AFQ bundle= \" + str(bundle_names_afq2[i]))\n",
    "    tmp = p_idx_afq[(num_sl*i):(num_sl-1)+(num_sl*i)]\n",
    "    m = stat.mode(tmp)\n",
    "    print(\"Most likely bundle= \" + str(bundle_names[m]))\n",
    "    tmp2 = prob[(num_sl*i):(num_sl-1)+(num_sl*i)]\n",
    "    p = np.mean(prob[(num_sl*i):(num_sl-1)+(num_sl*i)])\n",
    "    p2 = np.mean(tmp2[tmp==m])\n",
    "    print(\"Mean probability over all SLs= \" + str(p))\n",
    "    print(\"Mean probability over 'correct' SLs= \" + str(p2))\n",
    "    c = sum(tmp==m)\n",
    "    print(\"Fraction of SLs with this most likely class= \" + str(c/num_sl))\n",
    "    print(\"        \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlines_loaded_afqall = db.from_sequence([\"/home/ubuntu/stanford_hardi/derivatives/afq/sub-01/sess-01/sub-01_sess-01_dwiDTI_det_streamlines.trk\"]).map(bn.read_sl).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = bn.read_sl(\"/home/ubuntu/stanford_hardi/derivatives/afq/sub-01/sess-01/sub-01_sess-01_dwiDTI_det_streamlines.trk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlines_loaded_afqall = db.from_sequence([sl[0:10],sl[10:20]]).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlines_loaded_afqall = db.from_sequence([np.zeros([3,1]),np.zeros([3,1])]).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AFQ.utils.parallel import parfor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi_img = nib.load('/home/ubuntu/stanford_hardi/derivatives/afq/sub-01/sess-01/sub-01_sess-01_dwi_b0.nii.gz')\n",
    "vol_shape_dwi=dwi_img.shape\n",
    "vol_shape_dwi\n",
    "num_sl=-1\n",
    "size_slimage=100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time afq_all = parfor(bn.process_sl,[sl[i:i*30000] for i in range(10)],func_args=[num_sl,vol_shape_dwi,size_slimage,5],engine=\"dask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time afq_all2 = bn.process_sl(sl[0:60000],num_sl,vol_shape_dwi,size_slimage,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(afq_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(afq_all[0][1,:,:,:].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afq_all[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
